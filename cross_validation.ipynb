{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cross_validation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1k1VFO1nHXE--qfAR2Y2exVYpVMNDcmTJ",
      "authorship_tag": "ABX9TyMJe83jQKZobpwYDlPqWA/0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hwajun1323/ML/blob/master/cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lJjS99is-Fw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b45fcbbd-44bd-4524-9cd9-362fc54baef4"
      },
      "source": [
        "pip install keras-metrics"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-metrics\n",
            "  Downloading https://files.pythonhosted.org/packages/32/c9/a87420da8e73de944e63a8e9cdcfb1f03ca31a7c4cdcdbd45d2cdf13275a/keras_metrics-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.7/dist-packages (from keras-metrics) (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras-metrics) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras-metrics) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras-metrics) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras-metrics) (3.13)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->Keras>=2.1.5->keras-metrics) (1.5.2)\n",
            "Installing collected packages: keras-metrics\n",
            "Successfully installed keras-metrics-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ0gCXmlfZX8"
      },
      "source": [
        "import keras\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score , cross_validate\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import keras_metrics as km\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiVFsiIWffUd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86034d4-1b92-4802-b7d5-0c81fe6c1118"
      },
      "source": [
        "data_dir = \"/content/drive/My Drive/dataset/video_data\"\n",
        "#data_dir = \"video_data/\"\n",
        "img_height, img_width = 64, 64\n",
        "seq_len = 70\n",
        "\n",
        "classes = [\"Child's room\",  \"Museum\", \"Office\", \"Restaurant\"]\n",
        "num_classes = len(classes)\n",
        "print(\"Number of Class: \", num_classes)\n",
        "\n",
        "#  Creating frames from videos\n",
        "\n",
        "def frames_extraction(video_path):\n",
        "    frames_list = []\n",
        "\n",
        "    vidObj = cv2.VideoCapture(video_path)\n",
        "    # Used as counter variable\n",
        "    count = 1\n",
        "\n",
        "    while count <= seq_len:\n",
        "        success, image = vidObj.read()\n",
        "        if success:\n",
        "            image = cv2.resize(image, (img_height, img_width))\n",
        "            frames_list.append(image)\n",
        "            count += 1\n",
        "        else:\n",
        "            print(\"Defected frame\")\n",
        "            break\n",
        "\n",
        "    return frames_list\n",
        "\n",
        "# Create the actual data from the sequence of images\n",
        "\n",
        "def create_data(input_dir):\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    classes_list = os.listdir(input_dir)\n",
        "\n",
        "    for c in classes_list:\n",
        "        print(c)\n",
        "        files_list = os.listdir(os.path.join(input_dir, c))\n",
        "        for f in files_list:\n",
        "            frames = frames_extraction(os.path.join(os.path.join(input_dir, c), f))\n",
        "            if len(frames) == seq_len:\n",
        "                X.append(frames)\n",
        "\n",
        "                y = [0] * len(classes)\n",
        "                y[classes.index(c)] = 1\n",
        "                Y.append(y)\n",
        "\n",
        "    X = np.asarray(X)\n",
        "    Y = np.asarray(Y)\n",
        "    \n",
        "    return X, Y"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Class:  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6nClQdnRTwb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "074e8bef-5b0a-458c-afd1-7686db1f9dc5"
      },
      "source": [
        "X, Y = create_data(data_dir)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, shuffle=True, random_state=0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Child's room\n",
            "Restaurant\n",
            "Office\n",
            "Defected frame\n",
            "Defected frame\n",
            "Museum\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_ehqpr2ZCgm",
        "outputId": "df599008-f19c-4716-c3fa-2262ec8e8e83"
      },
      "source": [
        "# Cross validation\n",
        "\n",
        "skf = KFold(n_splits=5, shuffle=True, random_state=None)\n",
        "\n",
        "# X is the feature set and y is the target\n",
        "for train_index, test_index in skf.split(X,Y): \n",
        "    #print(\"Train:\", train_index, \"Validation:\", test_index) \n",
        "    X_train, X_test = X[train_index], X[test_index] \n",
        "    y_train, y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(817, 70, 64, 64, 3)\n",
            "(204, 70, 64, 64, 3)\n",
            "(817, 4)\n",
            "(204, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h_v-9iPAIv_E",
        "outputId": "3707ac4e-6793-4eb9-a1bb-c2feed90a417"
      },
      "source": [
        "def create_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(ConvLSTM2D(filters=64, kernel_size=(3, 3), return_sequences=False, data_format=\"channels_last\", input_shape=(seq_len, img_height, img_width, 3)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation=\"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    #model.add(Dense(256, activation=\"relu\"))\n",
        "    #model.add(Dropout(0.5))\n",
        "    model.add(Dense(128, activation=\"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # Various optimizer\n",
        "\n",
        "    #opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "    #opt = keras.optimizers.SGD(lr=0.001)\n",
        "    #opt = keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
        "    #opt = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
        "    #opt = keras.optimizers.Adagrad(lr=0.001, epsilon=1e-6)\n",
        "    opt = keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, epochs=60, batch_size=10, verbose=0)\n",
        "kfold = KFold(n_splits=2, shuffle=True, random_state=None) \n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "\n",
        "#score = cross_val_score(model, X, Y, scoring='accuracy', cv=5)\n",
        "print('cross validation accuracy:',np.round(results, 4))\n",
        "print('mean accuracy:', np.round(np.mean(results), 4))\n",
        "\n",
        "#earlystop = EarlyStopping(patience=7)\n",
        "#callbacks = [earlystop]\n",
        "\n",
        "#history = model.fit(x=X_train, y=y_train, epochs=40, batch_size=8, shuffle=True, validation_split=0.2, callbacks=callbacks)\n",
        "#history = model.fit(x=X_train, y=y_train, epochs=60, batch_size=10, shuffle=True, validation_split=0.2)\n",
        "print(\"Accuracy : %.4f\" % (model.evaluate(X_test, y_test)[1]))\n",
        "\n",
        "# Result\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"\\nLoss: {}, Acc: {}\".format(loss,acc))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_lst_m2d_1 (ConvLSTM2D)  (None, 62, 62, 64)        154624    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 62, 62, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 62, 62, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 204,932\n",
            "Trainable params: 204,804\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_lst_m2d_2 (ConvLSTM2D)  (None, 62, 62, 64)        154624    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 62, 62, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 62, 62, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 31, 31, 64)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 204,932\n",
            "Trainable params: 204,804\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "cross validation accuracy: [0.4364 0.2725]\n",
            "mean accuracy: 0.3545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b4e6fffa2459>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m#history = model.fit(x=X_train, y=y_train, epochs=40, batch_size=8, shuffle=True, validation_split=0.2, callbacks=callbacks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m#history = model.fit(x=X_train, y=y_train, epochs=60, batch_size=10, shuffle=True, validation_split=0.2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy : %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'evaluate'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYnev14UAi_m",
        "outputId": "8184b26c-2b6f-4ea7-d627-eed7d62c8b4b"
      },
      "source": [
        "# Result\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"\\nLoss: {}, Acc: {}\".format(loss,acc))\n",
        "\n",
        "# Evaluation of model\n",
        "y_pred = model.predict(X_test)\n",
        "# Classification Report\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Classification Report:\\n')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred) \n",
        "print('confusion matrix:\\n ', cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 3s 478ms/step - loss: 1.2351 - accuracy: 0.4634\n",
            "\n",
            "Loss: 1.2350788116455078, Acc: 0.46341463923454285\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.46      0.45        28\n",
            "           1       0.00      0.00      0.00        53\n",
            "           2       0.00      0.00      0.00        37\n",
            "           3       0.48      0.94      0.63        87\n",
            "\n",
            "    accuracy                           0.46       205\n",
            "   macro avg       0.23      0.35      0.27       205\n",
            "weighted avg       0.26      0.46      0.33       205\n",
            "\n",
            "confusion matrix:\n",
            "  [[13  0  0 15]\n",
            " [ 6  0  0 47]\n",
            " [ 6  3  0 28]\n",
            " [ 5  0  0 82]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "03EgVD9bI03A",
        "outputId": "0e541f4e-9018-4da4-d468-c30383e4b6d4"
      },
      "source": [
        "# Visualize the plot\n",
        "\n",
        "## summarize history for accuracy\n",
        "plt.plot(results.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "## summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d66ce919e2fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m## summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'history'"
          ]
        }
      ]
    }
  ]
}